{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import set_config ## SE AGREGA ESTO PARA QUE EL DIAGRAMA DEL PIPELINE APAREZCA INTERACTIVO\n",
    "set_config(display='diagram') ## SE AGREGA ESTO PARA QUE EL DIAGRAMA DEL PIPELINE APAREZCA INTERACTIVO\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.metrics import roc_auc_score, cohen_kappa_score, accuracy_score \n",
    "from  sklearn.base import clone ## Copiar un pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se verifica si hay datos duplicados\n",
    "train.loc[train.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se elimina la variable ID, no es relevante para el análisis\n",
    "train.drop('ID', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza y EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Control de calidad de los datos.\n",
    "En esta sección se realiza una revisión del tipo de variables y el número de datos faltantes en el data set de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = train.isnull().sum()[train.isnull().sum()>0].sort_values().plot(kind = 'barh')\n",
    "ax.bar_label(ax.containers[0])\n",
    "ax.set_title('Variables con valores nulos')\n",
    "ax.get_xaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum(axis = 1).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En el control de calidad de los datos, se encuentra que el dataset consta de 8.608 observaciones y 11 variables, las cuales todas tienen el tipo de variable esperado. \n",
    "\n",
    "* Con respecto a los datos faltantes, la variable ***Work_Experience*** es la que mayor cantidad de nulos tiene (829), seguido de ***Family_Size*** (335).\n",
    "\n",
    "* En cuanto a el número de nulos por observación se encuentra que, existen 6.665 registros completos, 1.244 registros con un dato faltante en 1 columna, 140 registros con datos faltantes en 2 columnas y 19 registros con al menos 3 columnas sin dato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SE DEFINE FUNCIÓN PARA SEPARAR LAS VARIABLES CATEGÓRICAS, NUMÉRICAS Y LA DEPENDIENTE\n",
    "def SepararNumCate(df : pd.DataFrame):\n",
    "    '''Returns a triplet with column names (numerical, categorical, target)\n",
    "    '''\n",
    "    numerical = df.select_dtypes(include = 'number').columns.to_list()\n",
    "    categorical = df.select_dtypes(exclude = 'number').columns.to_list()\n",
    "    categorical.remove('Segmentation') ## REMOVES THE TARGET VARIABLE\n",
    "    target = ['Segmentation']\n",
    "    return numerical, categorical, target\n",
    "\n",
    "\n",
    "num_idx, categ_idx, target_idx = SepararNumCate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identificar los valores únicos de las variables categóricas\n",
    "for i in train[categ_idx + target_idx].columns:\n",
    "    print(f'Categorías de la variable \"{i}\" ',train[i].unique(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para elegir qué se va a realizar con respecto a los valores faltantes se proponen 3 estrategias que se pondrán a prueba:\n",
    "\n",
    "> - 1. Un data set de entrenamiento eliminando todos las observaciones que tengan al menos 1 dato faltante, lo que representa quedarse con un 75% del data set de entrenamiento inicial.\n",
    "\n",
    "> - 2. Un data set de entrenamiento donde se eliminan las observaciones que tienen 2 o más datos nulos y a la observación que quede con dato un nulo se le asigna el valor del dato, mediante algún método de imputación.\n",
    "\n",
    "> - 3. Un data set donde no se elimina ningún registro, se asigna el valor de los datos por algún método de imputación.\n",
    "\n",
    "Después de entrenados los modelos (imputers), se realizará la evaluación del desempeño de los modelos empleando un **pipeline** \n",
    "//TODO ...mejorar esta redacción del pipe line y los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definimos los pipelines y la función por la cual va a pasar cada uno de los dataset de las anteriores estrategias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pipelines\n",
    "\n",
    "numerical_pipeline = Pipeline( steps = [\n",
    "    ('scaler',StandardScaler())\n",
    "])\n",
    "\n",
    "categ_pipeline = Pipeline( steps = [\n",
    "    ('encoder',OneHotEncoder(handle_unknown = 'ignore'))\n",
    "])\n",
    "\n",
    "## ColumnTransformer\n",
    "columnsTransf = ColumnTransformer(transformers = [\n",
    "                    ('numerical_pl',numerical_pipeline,num_idx),\n",
    "                    ('categorical_pl',categ_pipeline,categ_idx)\n",
    "                            ],\n",
    "                    remainder = 'drop'\n",
    "                                )\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state = 123)\n",
    "lr_model = LogisticRegression()\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "\n",
    "### Diccionario que contiene todos los pipelines\n",
    "pl_dict = { 'RandomForest' : Pipeline( steps = [\n",
    "                                    ('col_transf',columnsTransf),\n",
    "                                    ('model',rf_model)\n",
    "                                        ]),\n",
    "            'LogisticRegression' : Pipeline( steps = [\n",
    "                                    ('col_transf',columnsTransf),\n",
    "                                    ('model',lr_model)\n",
    "                                        ]),\n",
    "            'NaiveBayes' : Pipeline( steps = [\n",
    "                                    ('col_transf',columnsTransf),\n",
    "                                    ('model',nb_model)\n",
    "                                         ])\n",
    "           }\n",
    "\n",
    "## Crear el pipeline para la imputación\n",
    "num_imputer = Pipeline(steps = [\n",
    "        ('num_imputer',SimpleImputer(strategy = 'median')),\n",
    "])\n",
    "\n",
    "cat_imputer = Pipeline(steps = [\n",
    "    ('cat_imputer',SimpleImputer(strategy = 'most_frequent'))\n",
    "])\n",
    "\n",
    "columnImputer = ColumnTransformer(transformers = [\n",
    "    ('Numerical',num_imputer,num_idx),\n",
    "    ('Categorical', cat_imputer, categ_idx)\n",
    "                                ], \n",
    "            remainder = 'passthrough' ## En este caso no ponemos drop porque necesitamos nuestra variable objetivo, ya que este pipeline es sólo para transformar columna\n",
    ")\n",
    "\n",
    "imputer_pipe = Pipeline(steps=[\n",
    "    ('columns_transf',columnImputer)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "def ImputersTest(df : pd.DataFrame,  numerical_columns : list, \n",
    "                 categorical_columns : list, target : str, model : str): \n",
    "    if model in pl_dict.keys():\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df[numerical_columns + categorical_columns], df[target], test_size = 0.2, random_state = 123)\n",
    "        pipe = clone(pl_dict.get(model))\n",
    "        pipe.fit(X_train,y_train)\n",
    "        predictions_test = pipe.predict(X_test)\n",
    "        predictions_train = pipe.predict(X_train)\n",
    "        print(f'Accuracy_train : {accuracy_score(y_train, predictions_train)} \\nAccuracy_test : {accuracy_score(y_test, predictions_test)}')\n",
    "        return None\n",
    "    else:\n",
    "        print(f'{model} no es un modelo implementado, las opciones son {list(pl_dict.keys())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrategia 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay que hacer ningún tratamiento de imputación, sólo eliminar las filas que contengan NA's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train.dropna( axis = 0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImputersTest(train1 ,num_idx, categ_idx, target_idx, 'LogisticRegression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrategia 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se eliminan las filas que tienen datos faltantes en 2 o más de sus columnas\n",
    "train2 = train.drop(train.loc[train.isna().sum(axis = 1) >= 2].index).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_imp = pd.DataFrame(clone(imputer_pipe).fit_transform(train2), columns = num_idx + categ_idx + target_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImputersTest(train2_imp,num_idx,categ_idx,target_idx,'LogisticRegression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrategia 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3_imp = pd.DataFrame(clone(imputer_pipe).fit_transform(train3), columns = num_idx + categ_idx + target_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImputersTest(train3_imp,num_idx,categ_idx,target_idx,'LogisticRegression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separar variables para imputar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SEPARAMOS LAS VARIABLES CATEGÓRICAS Y NUMÉRICAS\n",
    "numerical_x = train[train.select_dtypes(include = 'number').columns].copy()\n",
    "categorical_x = train[train.select_dtypes(exclude = 'number').columns].drop('Segmentation', axis = 1).copy()\n",
    "y = train['Segmentation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SE ESTANDARIZAN LAS NUMÉRICAS Y SE HACE ONE HOT ENCODING CON LAS CATEGÓRICAS\n",
    "numerical_std = pd.DataFrame(StandardScaler().fit_transform(numerical_x), columns = numerical_x.columns)\n",
    "categorical_ohe = pd.get_dummies(categorical_x, dtype = np.int8)\n",
    "\n",
    "### SE UNEN AMBOS TIPOS DE VARIABLES\n",
    "x_1 = pd.concat([numerical_std, categorical_ohe], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  - SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_simpleImput = []\n",
    "\n",
    "for i in ['mean', 'median','most_frequent']: #### REVISAR ESTO TAMBIÉN\n",
    "    imputer = SimpleImputer(strategy = i)\n",
    "    x_simpImp = pd.DataFrame(imputer.fit_transform(x_1), columns = x_1.columns)\n",
    "    classifier = KNeighborsClassifier()\n",
    "    classifier.fit(x_simpImp, train['Segmentation'])\n",
    "    scores_simpleImput.append(cross_val_score(classifier,x_simpImp, train['Segmentation'], cv = 10, scoring = 'accuracy').mean())\n",
    "\n",
    "plt.plot(['mean', 'median','most_frequent'],scores_simpleImput)\n",
    "plt.title('Performance of different strategies on prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_KnnImp = []\n",
    "\n",
    "for i in range(1,10):\n",
    "    imputer = KNNImputer(n_neighbors = i)\n",
    "    x_KnnImp = pd.DataFrame(imputer.fit_transform(x_1), columns = x_1.columns)\n",
    "    classifier = KNeighborsClassifier()\n",
    "    classifier.fit(x_KnnImp, train['Segmentation'])\n",
    "    scores_KnnImp.append(cross_val_score(classifier,x_KnnImp, train['Segmentation'], cv = 10, scoring = 'accuracy').mean())\n",
    "\n",
    "plt.plot(range(1,10),scores_KnnImp)\n",
    "plt.title('Performance of different neighbors on prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Iterative Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_iterImp = []\n",
    "\n",
    "for i in range(1,10):\n",
    "    imputer = IterativeImputer(random_state = 123, n_nearest_features = i)\n",
    "    x_iterImp = pd.DataFrame(imputer.fit_transform(x_1), columns = x_1.columns)\n",
    "    classifier = KNeighborsClassifier()\n",
    "    classifier.fit(x_iterImp, train['Segmentation'])\n",
    "    scores_iterImp.append(cross_val_score(classifier,x_iterImp, train['Segmentation'], cv = 10, scoring = 'accuracy').mean())\n",
    "\n",
    "plt.plot(range(1,10),scores_iterImp)\n",
    "plt.title('Performance of different neighbors on prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  CLASIFICACIÓN ES MAYOR, PUESTO QUE ES EL ACCURACY\n",
    "\n",
    "scores_iterImp[np.argmax((scores_iterImp))] ### BEST SCORE OF ITERATIVE/MICE\n",
    "scores_KnnImp[np.argmax((scores_KnnImp))] ### BEST SCORE OF KNN IMPUTER\n",
    "scores_simpleImput[np.argmax((scores_simpleImput))] ### BEST SCORE OF SIMPLE IMPUTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EL MÉTODO QUE MEJOR RESULTADO ARROJÓ FUE EL KNEAREST NEIHGBORS IMPUTER CON 2 VECINOS\n",
    "\n",
    "imputer = KNNImputer(n_neighbors = 2) ## arreglar\n",
    "x_KnnImp = pd.DataFrame(imputer.fit_transform(x_1), columns = x_1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos predictivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_KnnImp, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rf_clsf = []\n",
    "\n",
    "for i in range(1,20,2):\n",
    "    rf_clsf = RandomForestClassifier(max_depth = i)\n",
    "    rf_clsf.fit(X_train,y_train)\n",
    "    score_rf_clsf.append(cross_val_score(rf_clsf, X_train, y_train, scoring = 'accuracy', cv = 10).mean())\n",
    "\n",
    "plt.plot(range(1,20,2),score_rf_clsf)\n",
    "plt.title('Accuracy of prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_knn_clsf = []\n",
    "\n",
    "for i in range(1,100,2):\n",
    "    knn_clsf = KNeighborsClassifier(n_neighbors = i)\n",
    "    knn_clsf.fit(X_train,y_train)\n",
    "    score_knn_clsf.append(cross_val_score(knn_clsf, X_train, y_train, scoring = 'accuracy', cv = 10).mean())\n",
    "\n",
    "plt.plot(range(1,100,2),score_knn_clsf)\n",
    "plt.title('Accuracy of prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//TODO ...Después de definir que forma de imputar se deja ya pasamos a las descriptivas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Visualización de la información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Balanceo de la variable dependiente**\n",
    "\n",
    "  Cada una de las categorías de la variable Segmentation contiene alrededor del 25% de las observaciones, por lo que al dataset no hay que realizarle procesos de balanceo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = train.Segmentation.value_counts(normalize = True).sort_index().plot( kind = 'bar')\n",
    "ax.get_yaxis().set_visible(False)\n",
    "labels = (train.Segmentation.value_counts(normalize = True).sort_index()*100).round(1).astype('str') + '%' ## ETIQUETA DE LAS BARRAS QUE SE MUESTRE EN %\n",
    "ax.tick_params(axis='x', rotation = 0)  ## ROTAR LAS ETIQUETAS DEL EJE X\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, labels = labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESCRIPCIÓN VARIABLES NUMÉRICAS VS VARIABLE DEPENDIENTE\n",
    "* **Segmentación vs Edad:**\n",
    "\n",
    "    En los siguientes gráficos se observa que el grupo D, tiene en promedio una edad menor que el resto de grupos, siendo esta alrededor de los 32 años. Los 3 grupos restantes tienen una edad promedio muy cercana a los 50 años.\n",
    "\n",
    "* **Segmentación vs Experiencia laboral**\n",
    "\n",
    "    En la gráfica siguiente se observa que el promedio de experiencia laboral para todas las categorías de Segmentation se encuentra entre los 2 y 3 años, también es posible identificar que el grupo D es el que más experiencia tiene puesto que un 75% de los individuos tienen una experiencia laboral de 6 años o menos, y el grupo C es el que menos experiencia tiene ya que el 75% de los individuos tienen una experiencia de 3 años o menos.\n",
    "\n",
    "\n",
    "* **Segmentation vs Family Size**\n",
    "\n",
    "  El tamaño del núcleo familiar tiene una distribución similar para los segmentos B, C y D, donde el 75% de los individuos cada uno de estos grupos tiene un núcleo familiar conformado por 4 o menos personas, por otra parte el núcleo familiar del Segmento A es más reducido donde el 75% de los individuos tienen un núcleo familiar de 3 o menos personas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1 ,ax2, ax3) = plt.subplots(1,3, figsize = (14,4))\n",
    "#sns.histplot(data = train, x  = 'Age', hue = 'Segmentation', kde = True, ax = ax1)\n",
    "sns.boxplot(data = train, x = 'Segmentation', y = 'Age',order = train.Segmentation.sort_values().unique(), ax = ax1, showmeans = True, palette = 'vlag')\n",
    "sns.boxplot(data = train, x = 'Segmentation', y = 'Work_Experience', order = train.Segmentation.sort_values().unique(), ax = ax2, showmeans = True,palette=\"vlag\")\n",
    "sns.boxplot(data = train, x = 'Segmentation', y = 'Family_Size', order = train.Segmentation.sort_values().unique(), ax = ax3, showmeans = True, palette=\"vlag\")\n",
    "# Calcular la media por categoría\n",
    "means = train.groupby('Segmentation')[['Age', 'Work_Experience', 'Family_Size']].mean().values\n",
    "\n",
    "# Agregar líneas para la media y la mediana\n",
    "#for i in range(len(train.Segmentation.sort_values().unique())):\n",
    " #   plt.text(i, means[i], f'{means[i]:.2f}', ha='center', va='bottom', color='blue', fontsize=8)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Género vs Segmentación**\n",
    "\n",
    "   Con respecto a la distribución del género por Segmentación, la participación en todos los grupos de ambos géneros es similar a excepción del grupo D, donde la participación de los hombres es casi del 60%.\n",
    "\n",
    "* **Ever_Married vs Segmentación**\n",
    "  \n",
    "  La variable categórica que toma en cuenta si el individuo ha estado casado alguna vez presenta la siguiente distribución: en los grupos A, B y C la mayoría de personas han estado casados, teniendo una mayor participación elos grupos A y B alcanzando casi el 80%. El grupo D por el contrario más del 70% de los individuos no han estado casados, este grupo como se vió en anteriores gráficas es el grupo con menor promedio de edad.\n",
    "  \n",
    "* **Graduated vs Segmentation**\n",
    "\n",
    "    La variable binaria que captura si el individuo se graduó sigue el comportamiento siguiente diferenciándola por la Segmentación: En los grupos A, B y C más del 60% son graduados, caso contrario en el grupo D donde poco más del 60% de los individuos no son graduados.\n",
    "\n",
    "* **Spending_Score vs Segmentation**\n",
    "    La variable categórica que captura si el puntaje de consumo es bajo, medio o alto presenta la siguiente distribución: Los grupos A, B y D predominan las personas que tienen un consumo bajo, siendo en el grupo D casi la totalidad de personas que tienen un consumo bajo, por su parte en el grupo C  predomina el consumo promedio con un poco más del 40%.\n",
    "\n",
    "* **Profession vs Segmentation**\n",
    "  \n",
    "  Con respecto a la profesión del cliente:\n",
    "    - El grupo A la mayor participación la tienen los artistas con casi el 30% de los individuos seguido de los profesionales del entretenimiento.\n",
    "    - El grupo B la mayor participación la tienen los artistas con más del 40% de los individuos seguido por los profesionales del entretenimiento.\n",
    "    - El grupo C la mayor participación la tienen los artistas con más del 50% de los individuos seguido por los ejecutivos.\n",
    "    - El grupo D la mayor participación la tienen los profesionales de la salud con más del 40% seguido por los doctores y profesionales del entretenamiento.\n",
    "     \n",
    "* **Var_1 vs Segmentation**\n",
    "\n",
    "  Con respecto a una categoría anónima que se le asigna a cada cliente la categoría 6 tiene la mayor participación en todos los segmentos con más del 60% de todos los individuos para los grupos A, B y C, y más del 50% en el grupo D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2),\n",
    "      (ax3, ax4),\n",
    "      (ax5, ax6)) = plt.subplots(3,2, figsize = (18,12), sharey = True)\n",
    "pd.crosstab(train.Segmentation,train.Gender,train.Age,aggfunc='count', normalize = 'index').plot(kind = 'bar', ax = ax1, edgecolor = 'black',colormap= 'vlag')\n",
    "ax1.get_yaxis().set_major_formatter(matplotlib.ticker.PercentFormatter(xmax = 1,decimals = 0))  ## MUESTRA LOS TICKS DEL EJE Y EN PORCENTAJE\n",
    "ax1.tick_params(axis='x', rotation=0)  ## ROTAR LAS ETIQUETAS DEL EJE X\n",
    "ax1.legend(loc = 'upper left', title = 'Gender')\n",
    "ax1.set_xlabel(None)\n",
    "\n",
    "pd.crosstab(train.Segmentation,train.Ever_Married,train.Age,aggfunc='count', normalize = 'index').plot(kind = 'bar', ax = ax2, edgecolor = 'black', colormap= 'vlag')\n",
    "ax2.get_yaxis().set_major_formatter(matplotlib.ticker.PercentFormatter(xmax = 1,decimals = 0))  ## MUESTRA LOS TICKS DEL EJE Y EN PORCENTAJE\n",
    "ax2.tick_params(axis='x', rotation=0) \n",
    "ax2.legend(loc = 'upper left')\n",
    "ax2.set_xlabel(None)\n",
    "\n",
    "pd.crosstab(train.Segmentation,train.Graduated,train.Age,aggfunc='count', normalize = 'index').plot(kind = 'bar', ax = ax3, edgecolor = 'black',colormap= 'vlag')\n",
    "ax3.get_yaxis().set_major_formatter(matplotlib.ticker.PercentFormatter(xmax = 1,decimals = 0))  ## MUESTRA LOS TICKS DEL EJE Y EN PORCENTAJE\n",
    "ax3.tick_params(axis='x', rotation=0)  ## ROTAR LAS ETIQUETAS DEL EJE X\n",
    "ax3.legend(loc = 'upper left', title = 'Graduated')\n",
    "ax3.set_xlabel(None)\n",
    "\n",
    "pd.crosstab(train.Segmentation,train.Spending_Score,train.Age,aggfunc='count', normalize = 'index').plot(kind = 'bar', ax = ax4, edgecolor = 'black',colormap= 'vlag')\n",
    "ax4.get_yaxis().set_major_formatter(matplotlib.ticker.PercentFormatter(xmax = 1,decimals = 0))  ## MUESTRA LOS TICKS DEL EJE Y EN PORCENTAJE\n",
    "ax4.tick_params(axis='x', rotation = 0) \n",
    "ax4.legend(loc = 'upper left')\n",
    "ax4.set_xlabel(None)\n",
    "\n",
    "pd.crosstab(train.Segmentation,train.Profession,train.Age,aggfunc='count', normalize = 'index').plot(kind = 'bar', ax = ax5, edgecolor = 'black',colormap= 'vlag')\n",
    "ax5.get_yaxis().set_major_formatter(matplotlib.ticker.PercentFormatter(xmax = 1,decimals = 0))  ## MUESTRA LOS TICKS DEL EJE Y EN PORCENTAJE\n",
    "ax5.tick_params(axis='x', rotation=0)  ## ROTAR LAS ETIQUETAS DEL EJE X\n",
    "ax5.legend(loc = 'upper left', ncols = 3)\n",
    "ax5.set_xlabel(None)\n",
    "\n",
    "pd.crosstab(train.Segmentation,train.Var_1,train.Age,aggfunc='count', normalize = 'index').plot(kind = 'bar', ax = ax6, edgecolor = 'black',colormap= 'vlag')\n",
    "ax6.get_yaxis().set_major_formatter(matplotlib.ticker.PercentFormatter(xmax = 1,decimals = 0))  ## MUESTRA LOS TICKS DEL EJE Y EN PORCENTAJE\n",
    "ax6.tick_params(axis='x', rotation=0) \n",
    "ax6.legend(loc = 'upper left', ncols = 3)\n",
    "ax6.set_xlabel(None)\n",
    "fig.suptitle('Variables categóricas vs variable objetivo', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_coeficiente_contingencia(df: pd.DataFrame, cols: list, target_col: str) -> pd.DataFrame:\n",
    "    resultados = []\n",
    "    for col in cols:\n",
    "        tabla_contingencia = pd.crosstab(df[col], df[target_col])\n",
    "        chi2, p, dof, expected = chi2_contingency(tabla_contingencia)\n",
    "        n = tabla_contingencia.values.sum()\n",
    "        coef_contingencia = np.sqrt(chi2 / (n * min(len(tabla_contingencia.index) - 1, len(tabla_contingencia.columns) - 1)))\n",
    "        resultados.append([col, coef_contingencia])\n",
    "    df_resultado = pd.DataFrame(resultados, columns=['Variable', 'Coeficiente de Contingencia'])\n",
    "    df_resultado.sort_values(by='Coeficiente de Contingencia', ascending=False, inplace=True)\n",
    "    df_resultado.reset_index(drop=True, inplace=True)\n",
    "    return df_resultado.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcular_coeficiente_contingencia(train1,categ_idx, 'Segmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación asociación entre variables categóricas independientes y variabel objetivo**\n",
    " - Todas las variables tienen un coeficiente menor a 0.6, por lo que ninguna presenta una asociación relativamente intensa con la variable objetivo. Sin embargo, la variable Ever_Married es la que mayor coeficiente de asociación tiene.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Extracción de información de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Comprensión y limpieza de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipelines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline sin nulos\n",
    "\n",
    "numerical_pipeline = Pipeline( steps = [\n",
    "    ('scaler',StandardScaler())\n",
    "])\n",
    "\n",
    "categ_pipeline = Pipeline( steps = [\n",
    "    ('encoder',OneHotEncoder(handle_unknown = 'ignore'))\n",
    "])\n",
    "\n",
    "## ColumnTransformer\n",
    "columnsTransf = ColumnTransformer(transformers = [\n",
    "                    ('numerical_pl',numerical_pipeline,num_idx),\n",
    "                    ('categorical_pl',categ_pipeline,categ_idx)\n",
    "                            ],\n",
    "                    remainder = 'drop'\n",
    "                                )\n",
    "rf_model = RandomForestClassifier(random_state = 123)\n",
    "\n",
    "rf_pipeline = Pipeline( steps = [\n",
    "    ('col_transf',columnsTransf),\n",
    "    ('model',rf_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MOSTRAR EL PIPELINE\n",
    "rf_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DIVIDIR EL DATASET\n",
    "X_train, X_test, y_train, y_test = train_test_split(train1[num_idx + categ_idx], train1[target_idx], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTRENAR EL MODELO\n",
    "rf_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OBTENER PREDICCIONES\n",
    "predictions = rf_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducción dimensionalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caracterización de los clientes por segmento"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
